python train_dist_backbone.py --dataset minc_seg --model fcn --aux --backbone resnet50s --batch-size 4
Namespace(aux=True, aux_weight=0.2, backbone='resnet50s', base_size=520, batch_size=4, checkname='default', crop_size=480, dataset='minc_seg', dist_backend='nccl', dist_url='tcp://localhost:23456', epochs=80, eval=False, export=None, ft=False, lr=0.001, lr_scheduler='poly', model='fcn', model_zoo=None, momentum=0.9, rank=0, rectify=False, rectify_avg=False, resume=None, se_loss=False, se_weight=0.2, seed=1, start_epoch=0, test_batch_size=16, test_folder=None, test_val=False, train_split='train', transfer=False, weight_decay=0.0001, workers=8, world_size=1)
rank: 0 / 1
BaseDataset: base_size 520, crop_size 480
/home/lzj/.encoding/data/minc_dataset/images/training
number of all parameter is
175
FCN(
  (pretrained): ResNet(
    (conv1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (bn1): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): DistSyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): DistSyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): GlobalAvgPool2d()
    (fc): None
  )
  (head): FCNHead(
    (conv5): Sequential(
      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): DistSyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.1, inplace=False)
      (4): Conv2d(512, 23, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (auxlayer): FCNHead(
    (conv5): Sequential(
      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): DistSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.1, inplace=False)
      (4): Conv2d(256, 23, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
Using poly LR scheduler with warm-up epochs of 0!
Starting Epoch: 0
Total Epoches: 80

=>Epoch 0, learning rate = 0.0010,                     previous best = 0.0000
Epoch: 0, Iter: 0, Speed: 0.061 iter/sec, Train loss: 3.750
Epoch: 0, Iter: 100, Speed: 1.729 iter/sec, Train loss: 3.167
Epoch: 0, Iter: 200, Speed: 1.688 iter/sec, Train loss: 2.949
Epoch: 0, Iter: 300, Speed: 1.663 iter/sec, Train loss: 2.797
pixAcc: 0.400, mIoU1: 0.050
pixAcc: 0.419, mIoU2: 0.074
Epoch: 0, Time cost: 265.7802240848541

=>Epoch 1, learning rate = 0.0010,                     previous best = 0.2468
Epoch: 1, Iter: 0, Speed: 0.086 iter/sec, Train loss: 4.020
Epoch: 1, Iter: 100, Speed: 1.657 iter/sec, Train loss: 2.280
Epoch: 1, Iter: 200, Speed: 1.631 iter/sec, Train loss: 2.345
Epoch: 1, Iter: 300, Speed: 1.623 iter/sec, Train loss: 2.317
Epoch: 1, Time cost: 255.26473712921143

=>Epoch 2, learning rate = 0.0010,                     previous best = 0.2468
Epoch: 2, Iter: 0, Speed: 0.090 iter/sec, Train loss: 1.120
Epoch: 2, Iter: 100, Speed: 1.646 iter/sec, Train loss: 2.083
Epoch: 2, Iter: 200, Speed: 1.618 iter/sec, Train loss: 2.052
Epoch: 2, Iter: 300, Speed: 1.627 iter/sec, Train loss: 2.054
Epoch: 2, Time cost: 255.8879611492157

=>Epoch 3, learning rate = 0.0010,                     previous best = 0.2468
Epoch: 3, Iter: 0, Speed: 0.089 iter/sec, Train loss: 2.305
Epoch: 3, Iter: 100, Speed: 1.664 iter/sec, Train loss: 1.974
Epoch: 3, Iter: 200, Speed: 1.644 iter/sec, Train loss: 1.921
Epoch: 3, Iter: 300, Speed: 1.655 iter/sec, Train loss: 1.905
Epoch: 3, Time cost: 252.68944883346558

=>Epoch 4, learning rate = 0.0010,                     previous best = 0.2468
Epoch: 4, Iter: 0, Speed: 0.088 iter/sec, Train loss: 2.120
Epoch: 4, Iter: 100, Speed: 1.647 iter/sec, Train loss: 1.634
Epoch: 4, Iter: 200, Speed: 1.618 iter/sec, Train loss: 1.638
Epoch: 4, Iter: 300, Speed: 1.627 iter/sec, Train loss: 1.690
Epoch: 4, Time cost: 256.6564817428589

=>Epoch 5, learning rate = 0.0009,                     previous best = 0.2468
Epoch: 5, Iter: 0, Speed: 0.089 iter/sec, Train loss: 1.257
Epoch: 5, Iter: 100, Speed: 1.649 iter/sec, Train loss: 1.574
Epoch: 5, Iter: 200, Speed: 1.612 iter/sec, Train loss: 1.622
Epoch: 5, Iter: 300, Speed: 1.628 iter/sec, Train loss: 1.652
Epoch: 5, Time cost: 256.67878222465515

=>Epoch 6, learning rate = 0.0009,                     previous best = 0.2468
Epoch: 6, Iter: 0, Speed: 0.090 iter/sec, Train loss: 1.636
Epoch: 6, Iter: 100, Speed: 1.649 iter/sec, Train loss: 1.433
Epoch: 6, Iter: 200, Speed: 1.614 iter/sec, Train loss: 1.470
Epoch: 6, Iter: 300, Speed: 1.627 iter/sec, Train loss: 1.474
Epoch: 6, Time cost: 256.6547689437866

=>Epoch 7, learning rate = 0.0009,                     previous best = 0.2468
Epoch: 7, Iter: 0, Speed: 0.086 iter/sec, Train loss: 1.191
Epoch: 7, Iter: 100, Speed: 1.677 iter/sec, Train loss: 1.310
Epoch: 7, Iter: 200, Speed: 1.645 iter/sec, Train loss: 1.316
Epoch: 7, Iter: 300, Speed: 1.651 iter/sec, Train loss: 1.363
Epoch: 7, Time cost: 252.82499527931213

=>Epoch 8, learning rate = 0.0009,                     previous best = 0.2468
Epoch: 8, Iter: 0, Speed: 0.088 iter/sec, Train loss: 1.138
Epoch: 8, Iter: 100, Speed: 1.651 iter/sec, Train loss: 1.271
Epoch: 8, Iter: 200, Speed: 1.617 iter/sec, Train loss: 1.332
Epoch: 8, Iter: 300, Speed: 1.622 iter/sec, Train loss: 1.333
Epoch: 8, Time cost: 256.9529447555542

=>Epoch 9, learning rate = 0.0009,                     previous best = 0.2468
Epoch: 9, Iter: 0, Speed: 0.087 iter/sec, Train loss: 1.160
Epoch: 9, Iter: 100, Speed: 1.646 iter/sec, Train loss: 1.280
Epoch: 9, Iter: 200, Speed: 1.613 iter/sec, Train loss: 1.314
Epoch: 9, Iter: 300, Speed: 1.640 iter/sec, Train loss: 1.262
Epoch: 9, Time cost: 255.35379910469055

=>Epoch 10, learning rate = 0.0009,                     previous best = 0.2468
Epoch: 10, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.918
Epoch: 10, Iter: 100, Speed: 1.648 iter/sec, Train loss: 1.312
Epoch: 10, Iter: 200, Speed: 1.615 iter/sec, Train loss: 1.252
Epoch: 10, Iter: 300, Speed: 1.624 iter/sec, Train loss: 1.227
pixAcc: 0.714, mIoU1: 0.183
pixAcc: 0.650, mIoU2: 0.357
Epoch: 10, Time cost: 270.2282965183258

=>Epoch 11, learning rate = 0.0009,                     previous best = 0.5037
Epoch: 11, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.570
Epoch: 11, Iter: 100, Speed: 1.677 iter/sec, Train loss: 1.170
Epoch: 11, Iter: 200, Speed: 1.642 iter/sec, Train loss: 1.103
Epoch: 11, Iter: 300, Speed: 1.650 iter/sec, Train loss: 1.100
Epoch: 11, Time cost: 252.5427565574646

=>Epoch 12, learning rate = 0.0009,                     previous best = 0.5037
Epoch: 12, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.794
Epoch: 12, Iter: 100, Speed: 1.649 iter/sec, Train loss: 1.187
Epoch: 12, Iter: 200, Speed: 1.617 iter/sec, Train loss: 1.119
Epoch: 12, Iter: 300, Speed: 1.625 iter/sec, Train loss: 1.141
Epoch: 12, Time cost: 255.9885754585266

=>Epoch 13, learning rate = 0.0009,                     previous best = 0.5037
Epoch: 13, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.470
Epoch: 13, Iter: 100, Speed: 1.644 iter/sec, Train loss: 0.992
Epoch: 13, Iter: 200, Speed: 1.616 iter/sec, Train loss: 1.043
Epoch: 13, Iter: 300, Speed: 1.623 iter/sec, Train loss: 1.016
Epoch: 13, Time cost: 256.18359780311584

=>Epoch 14, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 14, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.702
Epoch: 14, Iter: 100, Speed: 1.646 iter/sec, Train loss: 1.064
Epoch: 14, Iter: 200, Speed: 1.616 iter/sec, Train loss: 1.017
Epoch: 14, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.969
Epoch: 14, Time cost: 256.9794888496399

=>Epoch 15, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 15, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.499
Epoch: 15, Iter: 100, Speed: 1.672 iter/sec, Train loss: 0.825
Epoch: 15, Iter: 200, Speed: 1.644 iter/sec, Train loss: 0.917
Epoch: 15, Iter: 300, Speed: 1.652 iter/sec, Train loss: 0.918
Epoch: 15, Time cost: 252.90170121192932

=>Epoch 16, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 16, Iter: 0, Speed: 0.086 iter/sec, Train loss: 1.031
Epoch: 16, Iter: 100, Speed: 1.658 iter/sec, Train loss: 0.963
Epoch: 16, Iter: 200, Speed: 1.646 iter/sec, Train loss: 0.913
Epoch: 16, Iter: 300, Speed: 1.653 iter/sec, Train loss: 0.922
Epoch: 16, Time cost: 252.47748374938965

=>Epoch 17, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 17, Iter: 0, Speed: 0.089 iter/sec, Train loss: 1.019
Epoch: 17, Iter: 100, Speed: 1.646 iter/sec, Train loss: 0.905
Epoch: 17, Iter: 200, Speed: 1.617 iter/sec, Train loss: 0.840
Epoch: 17, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.854
Epoch: 17, Time cost: 256.55622935295105

=>Epoch 18, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 18, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.416
Epoch: 18, Iter: 100, Speed: 1.654 iter/sec, Train loss: 0.942
Epoch: 18, Iter: 200, Speed: 1.615 iter/sec, Train loss: 0.828
Epoch: 18, Iter: 300, Speed: 1.626 iter/sec, Train loss: 0.858
Epoch: 18, Time cost: 256.5377883911133

=>Epoch 19, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 19, Iter: 0, Speed: 0.088 iter/sec, Train loss: 1.201
Epoch: 19, Iter: 100, Speed: 1.647 iter/sec, Train loss: 0.813
Epoch: 19, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.784
Epoch: 19, Iter: 300, Speed: 1.628 iter/sec, Train loss: 0.777
Epoch: 19, Time cost: 256.7660231590271

=>Epoch 20, learning rate = 0.0008,                     previous best = 0.5037
Epoch: 20, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.470
Epoch: 20, Iter: 100, Speed: 1.672 iter/sec, Train loss: 0.729
Epoch: 20, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.669
Epoch: 20, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.664
pixAcc: 0.682, mIoU1: 0.205
pixAcc: 0.717, mIoU2: 0.428
Epoch: 20, Time cost: 269.2967994213104

=>Epoch 21, learning rate = 0.0008,                     previous best = 0.5727
Epoch: 21, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.655
Epoch: 21, Iter: 100, Speed: 1.660 iter/sec, Train loss: 0.626
Epoch: 21, Iter: 200, Speed: 1.636 iter/sec, Train loss: 0.670
Epoch: 21, Iter: 300, Speed: 1.640 iter/sec, Train loss: 0.670
Epoch: 21, Time cost: 254.38162875175476

=>Epoch 22, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 22, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.436
Epoch: 22, Iter: 100, Speed: 1.638 iter/sec, Train loss: 0.623
Epoch: 22, Iter: 200, Speed: 1.603 iter/sec, Train loss: 0.593
Epoch: 22, Iter: 300, Speed: 1.620 iter/sec, Train loss: 0.644
Epoch: 22, Time cost: 258.0816869735718

=>Epoch 23, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 23, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.345
Epoch: 23, Iter: 100, Speed: 1.671 iter/sec, Train loss: 0.560
Epoch: 23, Iter: 200, Speed: 1.629 iter/sec, Train loss: 0.597
Epoch: 23, Iter: 300, Speed: 1.640 iter/sec, Train loss: 0.632
Epoch: 23, Time cost: 255.2107973098755

=>Epoch 24, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 24, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.179
Epoch: 24, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.552
Epoch: 24, Iter: 200, Speed: 1.617 iter/sec, Train loss: 0.541
Epoch: 24, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.590
Epoch: 24, Time cost: 256.97692918777466

=>Epoch 25, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 25, Iter: 0, Speed: 0.087 iter/sec, Train loss: 2.253
Epoch: 25, Iter: 100, Speed: 1.662 iter/sec, Train loss: 0.599
Epoch: 25, Iter: 200, Speed: 1.642 iter/sec, Train loss: 0.560
Epoch: 25, Iter: 300, Speed: 1.653 iter/sec, Train loss: 0.591
Epoch: 25, Time cost: 253.32496809959412

=>Epoch 26, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 26, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.351
Epoch: 26, Iter: 100, Speed: 1.644 iter/sec, Train loss: 0.474
Epoch: 26, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.522
Epoch: 26, Iter: 300, Speed: 1.627 iter/sec, Train loss: 0.515
Epoch: 26, Time cost: 257.62115716934204

=>Epoch 27, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 27, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.948
Epoch: 27, Iter: 100, Speed: 1.646 iter/sec, Train loss: 0.428
Epoch: 27, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.464
Epoch: 27, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.500
Epoch: 27, Time cost: 257.37017369270325

=>Epoch 28, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 28, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.276
Epoch: 28, Iter: 100, Speed: 1.640 iter/sec, Train loss: 0.499
Epoch: 28, Iter: 200, Speed: 1.615 iter/sec, Train loss: 0.500
Epoch: 28, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.478
Epoch: 28, Time cost: 257.1501610279083

=>Epoch 29, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 29, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.428
Epoch: 29, Iter: 100, Speed: 1.642 iter/sec, Train loss: 0.500
Epoch: 29, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.482
Epoch: 29, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.502
Epoch: 29, Time cost: 257.1891973018646

=>Epoch 30, learning rate = 0.0007,                     previous best = 0.5727
Epoch: 30, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.469
Epoch: 30, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.439
Epoch: 30, Iter: 200, Speed: 1.613 iter/sec, Train loss: 0.451
Epoch: 30, Iter: 300, Speed: 1.625 iter/sec, Train loss: 0.478
pixAcc: 0.767, mIoU1: 0.212
pixAcc: 0.712, mIoU2: 0.451
Epoch: 30, Time cost: 269.51830315589905

=>Epoch 31, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 31, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.212
Epoch: 31, Iter: 100, Speed: 1.642 iter/sec, Train loss: 0.434
Epoch: 31, Iter: 200, Speed: 1.609 iter/sec, Train loss: 0.459
Epoch: 31, Iter: 300, Speed: 1.620 iter/sec, Train loss: 0.458
Epoch: 31, Time cost: 257.5445132255554

=>Epoch 32, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 32, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.324
Epoch: 32, Iter: 100, Speed: 1.646 iter/sec, Train loss: 0.396
Epoch: 32, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.435
Epoch: 32, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.436
Epoch: 32, Time cost: 257.10722303390503

=>Epoch 33, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 33, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.296
Epoch: 33, Iter: 100, Speed: 1.666 iter/sec, Train loss: 0.351
Epoch: 33, Iter: 200, Speed: 1.644 iter/sec, Train loss: 0.359
Epoch: 33, Iter: 300, Speed: 1.644 iter/sec, Train loss: 0.364
Epoch: 33, Time cost: 254.43774509429932

=>Epoch 34, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 34, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.273
Epoch: 34, Iter: 100, Speed: 1.663 iter/sec, Train loss: 0.317
Epoch: 34, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.320
Epoch: 34, Iter: 300, Speed: 1.626 iter/sec, Train loss: 0.363
Epoch: 34, Time cost: 255.2309079170227

=>Epoch 35, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 35, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.351
Epoch: 35, Iter: 100, Speed: 1.646 iter/sec, Train loss: 0.339
Epoch: 35, Iter: 200, Speed: 1.643 iter/sec, Train loss: 0.356
Epoch: 35, Iter: 300, Speed: 1.652 iter/sec, Train loss: 0.387
Epoch: 35, Time cost: 253.8865351676941

=>Epoch 36, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 36, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.227
Epoch: 36, Iter: 100, Speed: 1.669 iter/sec, Train loss: 0.320
Epoch: 36, Iter: 200, Speed: 1.641 iter/sec, Train loss: 0.324
Epoch: 36, Iter: 300, Speed: 1.655 iter/sec, Train loss: 0.361
Epoch: 36, Time cost: 252.618510723114

=>Epoch 37, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 37, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.275
Epoch: 37, Iter: 100, Speed: 1.663 iter/sec, Train loss: 0.327
Epoch: 37, Iter: 200, Speed: 1.642 iter/sec, Train loss: 0.307
Epoch: 37, Iter: 300, Speed: 1.651 iter/sec, Train loss: 0.329
Epoch: 37, Time cost: 255.5229434967041

=>Epoch 38, learning rate = 0.0006,                     previous best = 0.5816
Epoch: 38, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.080
Epoch: 38, Iter: 100, Speed: 1.632 iter/sec, Train loss: 0.368
Epoch: 38, Iter: 200, Speed: 1.567 iter/sec, Train loss: 0.406
Epoch: 38, Iter: 300, Speed: 1.549 iter/sec, Train loss: 0.380
Epoch: 38, Time cost: 263.5157687664032

=>Epoch 39, learning rate = 0.0005,                     previous best = 0.5816
Epoch: 39, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.333
Epoch: 39, Iter: 100, Speed: 1.609 iter/sec, Train loss: 0.287
Epoch: 39, Iter: 200, Speed: 1.593 iter/sec, Train loss: 0.278
Epoch: 39, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.292
Epoch: 39, Time cost: 260.2828588485718

=>Epoch 40, learning rate = 0.0005,                     previous best = 0.5816
Epoch: 40, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.188
Epoch: 40, Iter: 100, Speed: 1.632 iter/sec, Train loss: 0.366
Epoch: 40, Iter: 200, Speed: 1.588 iter/sec, Train loss: 0.339
Epoch: 40, Iter: 300, Speed: 1.610 iter/sec, Train loss: 0.323
pixAcc: 0.821, mIoU1: 0.221
pixAcc: 0.758, mIoU2: 0.495
Epoch: 40, Time cost: 272.751806974411

=>Epoch 41, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 41, Iter: 0, Speed: 0.084 iter/sec, Train loss: 0.401
Epoch: 41, Iter: 100, Speed: 1.576 iter/sec, Train loss: 0.306
Epoch: 41, Iter: 200, Speed: 1.567 iter/sec, Train loss: 0.295
Epoch: 41, Iter: 300, Speed: 1.564 iter/sec, Train loss: 0.279
Epoch: 41, Time cost: 266.2510395050049

=>Epoch 42, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 42, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.225
Epoch: 42, Iter: 100, Speed: 1.622 iter/sec, Train loss: 0.233
Epoch: 42, Iter: 200, Speed: 1.600 iter/sec, Train loss: 0.238
Epoch: 42, Iter: 300, Speed: 1.615 iter/sec, Train loss: 0.273
Epoch: 42, Time cost: 259.07113885879517

=>Epoch 43, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 43, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.232
Epoch: 43, Iter: 100, Speed: 1.658 iter/sec, Train loss: 0.326
Epoch: 43, Iter: 200, Speed: 1.600 iter/sec, Train loss: 0.299
Epoch: 43, Iter: 300, Speed: 1.613 iter/sec, Train loss: 0.282
Epoch: 43, Time cost: 257.0759541988373

=>Epoch 44, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 44, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.425
Epoch: 44, Iter: 100, Speed: 1.632 iter/sec, Train loss: 0.269
Epoch: 44, Iter: 200, Speed: 1.619 iter/sec, Train loss: 0.332
Epoch: 44, Iter: 300, Speed: 1.621 iter/sec, Train loss: 0.315
Epoch: 44, Time cost: 255.69776344299316

=>Epoch 45, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 45, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.406
Epoch: 45, Iter: 100, Speed: 1.635 iter/sec, Train loss: 0.261
Epoch: 45, Iter: 200, Speed: 1.610 iter/sec, Train loss: 0.257
Epoch: 45, Iter: 300, Speed: 1.640 iter/sec, Train loss: 0.248
Epoch: 45, Time cost: 256.8689305782318

=>Epoch 46, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 46, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.269
Epoch: 46, Iter: 100, Speed: 1.641 iter/sec, Train loss: 0.203
Epoch: 46, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.206
Epoch: 46, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.219
Epoch: 46, Time cost: 257.3199439048767

=>Epoch 47, learning rate = 0.0005,                     previous best = 0.6263
Epoch: 47, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.087
Epoch: 47, Iter: 100, Speed: 1.660 iter/sec, Train loss: 0.200
Epoch: 47, Iter: 200, Speed: 1.630 iter/sec, Train loss: 0.199
Epoch: 47, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.206
Epoch: 47, Time cost: 255.92803287506104

=>Epoch 48, learning rate = 0.0004,                     previous best = 0.6263
Epoch: 48, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.336
Epoch: 48, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.240
Epoch: 48, Iter: 200, Speed: 1.615 iter/sec, Train loss: 0.213
Epoch: 48, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.223
Epoch: 48, Time cost: 256.3274881839752

=>Epoch 49, learning rate = 0.0004,                     previous best = 0.6263
Epoch: 49, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.252
Epoch: 49, Iter: 100, Speed: 1.654 iter/sec, Train loss: 0.202
Epoch: 49, Iter: 200, Speed: 1.643 iter/sec, Train loss: 0.189
Epoch: 49, Iter: 300, Speed: 1.656 iter/sec, Train loss: 0.186
Epoch: 49, Time cost: 253.17231392860413

=>Epoch 50, learning rate = 0.0004,                     previous best = 0.6263
Epoch: 50, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.092
Epoch: 50, Iter: 100, Speed: 1.641 iter/sec, Train loss: 0.210
Epoch: 50, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.198
Epoch: 50, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.200
pixAcc: 0.669, mIoU1: 0.206
pixAcc: 0.762, mIoU2: 0.507
Epoch: 50, Time cost: 270.05761218070984

=>Epoch 51, learning rate = 0.0004,                     previous best = 0.6347
Epoch: 51, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.305
Epoch: 51, Iter: 100, Speed: 1.673 iter/sec, Train loss: 0.194
Epoch: 51, Iter: 200, Speed: 1.635 iter/sec, Train loss: 0.181
Epoch: 51, Iter: 300, Speed: 1.636 iter/sec, Train loss: 0.209
Epoch: 51, Time cost: 253.1834831237793

=>Epoch 52, learning rate = 0.0004,                     previous best = 0.6347
Epoch: 52, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.075
Epoch: 52, Iter: 100, Speed: 1.639 iter/sec, Train loss: 0.222
Epoch: 52, Iter: 200, Speed: 1.618 iter/sec, Train loss: 0.218
Epoch: 52, Iter: 300, Speed: 1.628 iter/sec, Train loss: 0.209
Epoch: 52, Time cost: 256.87730407714844

=>Epoch 53, learning rate = 0.0004,                     previous best = 0.6347
Epoch: 53, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.134
Epoch: 53, Iter: 100, Speed: 1.640 iter/sec, Train loss: 0.179
Epoch: 53, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.171
Epoch: 53, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.172
Epoch: 53, Time cost: 257.14866828918457

=>Epoch 54, learning rate = 0.0004,                     previous best = 0.6347
Epoch: 54, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.228
Epoch: 54, Iter: 100, Speed: 1.658 iter/sec, Train loss: 0.193
Epoch: 54, Iter: 200, Speed: 1.610 iter/sec, Train loss: 0.172
Epoch: 54, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.165
Epoch: 54, Time cost: 257.34973430633545

=>Epoch 55, learning rate = 0.0004,                     previous best = 0.6347
Epoch: 55, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.197
Epoch: 55, Iter: 100, Speed: 1.649 iter/sec, Train loss: 0.165
Epoch: 55, Iter: 200, Speed: 1.634 iter/sec, Train loss: 0.153
Epoch: 55, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.152
Epoch: 55, Time cost: 256.1339704990387

=>Epoch 56, learning rate = 0.0003,                     previous best = 0.6347
Epoch: 56, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.034
Epoch: 56, Iter: 100, Speed: 1.641 iter/sec, Train loss: 0.167
Epoch: 56, Iter: 200, Speed: 1.608 iter/sec, Train loss: 0.170
Epoch: 56, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.208
Epoch: 56, Time cost: 255.75025820732117

=>Epoch 57, learning rate = 0.0003,                     previous best = 0.6347
Epoch: 57, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.194
Epoch: 57, Iter: 100, Speed: 1.669 iter/sec, Train loss: 0.165
Epoch: 57, Iter: 200, Speed: 1.644 iter/sec, Train loss: 0.170
Epoch: 57, Iter: 300, Speed: 1.657 iter/sec, Train loss: 0.174
Epoch: 57, Time cost: 252.51467657089233

=>Epoch 58, learning rate = 0.0003,                     previous best = 0.6347
Epoch: 58, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.134
Epoch: 58, Iter: 100, Speed: 1.636 iter/sec, Train loss: 0.136
Epoch: 58, Iter: 200, Speed: 1.636 iter/sec, Train loss: 0.133
Epoch: 58, Iter: 300, Speed: 1.651 iter/sec, Train loss: 0.150
Epoch: 58, Time cost: 255.60754251480103

=>Epoch 59, learning rate = 0.0003,                     previous best = 0.6347
Epoch: 59, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.092
Epoch: 59, Iter: 100, Speed: 1.670 iter/sec, Train loss: 0.130
Epoch: 59, Iter: 200, Speed: 1.638 iter/sec, Train loss: 0.157
Epoch: 59, Iter: 300, Speed: 1.644 iter/sec, Train loss: 0.159
Epoch: 59, Time cost: 254.22176051139832

=>Epoch 60, learning rate = 0.0003,                     previous best = 0.6347
Epoch: 60, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.090
Epoch: 60, Iter: 100, Speed: 1.637 iter/sec, Train loss: 0.156
Epoch: 60, Iter: 200, Speed: 1.610 iter/sec, Train loss: 0.143
Epoch: 60, Iter: 300, Speed: 1.625 iter/sec, Train loss: 0.142
pixAcc: 0.808, mIoU1: 0.233
pixAcc: 0.769, mIoU2: 0.505
Epoch: 60, Time cost: 270.55255460739136

=>Epoch 61, learning rate = 0.0003,                     previous best = 0.6367
Epoch: 61, Iter: 0, Speed: 0.085 iter/sec, Train loss: 0.214
Epoch: 61, Iter: 100, Speed: 1.647 iter/sec, Train loss: 0.143
Epoch: 61, Iter: 200, Speed: 1.605 iter/sec, Train loss: 0.147
Epoch: 61, Iter: 300, Speed: 1.615 iter/sec, Train loss: 0.144
Epoch: 61, Time cost: 258.2077085971832

=>Epoch 62, learning rate = 0.0003,                     previous best = 0.6367
Epoch: 62, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.047
Epoch: 62, Iter: 100, Speed: 1.674 iter/sec, Train loss: 0.138
Epoch: 62, Iter: 200, Speed: 1.631 iter/sec, Train loss: 0.134
Epoch: 62, Iter: 300, Speed: 1.622 iter/sec, Train loss: 0.136
Epoch: 62, Time cost: 255.6270146369934

=>Epoch 63, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 63, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.049
Epoch: 63, Iter: 100, Speed: 1.668 iter/sec, Train loss: 0.132
Epoch: 63, Iter: 200, Speed: 1.639 iter/sec, Train loss: 0.127
Epoch: 63, Iter: 300, Speed: 1.650 iter/sec, Train loss: 0.129
Epoch: 63, Time cost: 253.59549927711487

=>Epoch 64, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 64, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.086
Epoch: 64, Iter: 100, Speed: 1.641 iter/sec, Train loss: 0.137
Epoch: 64, Iter: 200, Speed: 1.632 iter/sec, Train loss: 0.130
Epoch: 64, Iter: 300, Speed: 1.655 iter/sec, Train loss: 0.127
Epoch: 64, Time cost: 253.96394777297974

=>Epoch 65, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 65, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.039
Epoch: 65, Iter: 100, Speed: 1.636 iter/sec, Train loss: 0.138
Epoch: 65, Iter: 200, Speed: 1.621 iter/sec, Train loss: 0.124
Epoch: 65, Iter: 300, Speed: 1.625 iter/sec, Train loss: 0.127
Epoch: 65, Time cost: 256.25564670562744

=>Epoch 66, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 66, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.093
Epoch: 66, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.118
Epoch: 66, Iter: 200, Speed: 1.616 iter/sec, Train loss: 0.116
Epoch: 66, Iter: 300, Speed: 1.654 iter/sec, Train loss: 0.134
Epoch: 66, Time cost: 253.80977177619934

=>Epoch 67, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 67, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.058
Epoch: 67, Iter: 100, Speed: 1.640 iter/sec, Train loss: 0.119
Epoch: 67, Iter: 200, Speed: 1.640 iter/sec, Train loss: 0.116
Epoch: 67, Iter: 300, Speed: 1.654 iter/sec, Train loss: 0.117
Epoch: 67, Time cost: 255.78782677650452

=>Epoch 68, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 68, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.128
Epoch: 68, Iter: 100, Speed: 1.629 iter/sec, Train loss: 0.112
Epoch: 68, Iter: 200, Speed: 1.614 iter/sec, Train loss: 0.113
Epoch: 68, Iter: 300, Speed: 1.626 iter/sec, Train loss: 0.111
Epoch: 68, Time cost: 257.46320104599

=>Epoch 69, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 69, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.104
Epoch: 69, Iter: 100, Speed: 1.635 iter/sec, Train loss: 0.121
Epoch: 69, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.130
Epoch: 69, Iter: 300, Speed: 1.619 iter/sec, Train loss: 0.123
Epoch: 69, Time cost: 257.07387232780457

=>Epoch 70, learning rate = 0.0002,                     previous best = 0.6367
Epoch: 70, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.165
Epoch: 70, Iter: 100, Speed: 1.641 iter/sec, Train loss: 0.107
Epoch: 70, Iter: 200, Speed: 1.611 iter/sec, Train loss: 0.108
Epoch: 70, Iter: 300, Speed: 1.625 iter/sec, Train loss: 0.107
pixAcc: 0.801, mIoU1: 0.232
pixAcc: 0.774, mIoU2: 0.511
Epoch: 70, Time cost: 270.95289969444275

=>Epoch 71, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 71, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.075
Epoch: 71, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.127
Epoch: 71, Iter: 200, Speed: 1.606 iter/sec, Train loss: 0.117
Epoch: 71, Iter: 300, Speed: 1.618 iter/sec, Train loss: 0.117
Epoch: 71, Time cost: 256.01247477531433

=>Epoch 72, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 72, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.063
Epoch: 72, Iter: 100, Speed: 1.651 iter/sec, Train loss: 0.109
Epoch: 72, Iter: 200, Speed: 1.614 iter/sec, Train loss: 0.099
Epoch: 72, Iter: 300, Speed: 1.659 iter/sec, Train loss: 0.100
Epoch: 72, Time cost: 254.2683641910553

=>Epoch 73, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 73, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.078
Epoch: 73, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.121
Epoch: 73, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.121
Epoch: 73, Iter: 300, Speed: 1.623 iter/sec, Train loss: 0.112
Epoch: 73, Time cost: 256.28260827064514

=>Epoch 74, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 74, Iter: 0, Speed: 0.090 iter/sec, Train loss: 0.033
Epoch: 74, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.096
Epoch: 74, Iter: 200, Speed: 1.645 iter/sec, Train loss: 0.098
Epoch: 74, Iter: 300, Speed: 1.657 iter/sec, Train loss: 0.097
Epoch: 74, Time cost: 253.2303683757782

=>Epoch 75, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 75, Iter: 0, Speed: 0.089 iter/sec, Train loss: 0.185
Epoch: 75, Iter: 100, Speed: 1.664 iter/sec, Train loss: 0.098
Epoch: 75, Iter: 200, Speed: 1.628 iter/sec, Train loss: 0.103
Epoch: 75, Iter: 300, Speed: 1.643 iter/sec, Train loss: 0.099
Epoch: 75, Time cost: 254.50737285614014

=>Epoch 76, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 76, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.079
Epoch: 76, Iter: 100, Speed: 1.656 iter/sec, Train loss: 0.103
Epoch: 76, Iter: 200, Speed: 1.612 iter/sec, Train loss: 0.099
Epoch: 76, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.103
Epoch: 76, Time cost: 256.8971185684204

=>Epoch 77, learning rate = 0.0001,                     previous best = 0.6422
Epoch: 77, Iter: 0, Speed: 0.087 iter/sec, Train loss: 0.083
Epoch: 77, Iter: 100, Speed: 1.642 iter/sec, Train loss: 0.100
Epoch: 77, Iter: 200, Speed: 1.613 iter/sec, Train loss: 0.103
Epoch: 77, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.104
Epoch: 77, Time cost: 256.40965938568115

=>Epoch 78, learning rate = 0.0000,                     previous best = 0.6422
Epoch: 78, Iter: 0, Speed: 0.086 iter/sec, Train loss: 0.073
Epoch: 78, Iter: 100, Speed: 1.642 iter/sec, Train loss: 0.089
Epoch: 78, Iter: 200, Speed: 1.614 iter/sec, Train loss: 0.091
Epoch: 78, Iter: 300, Speed: 1.642 iter/sec, Train loss: 0.095
Epoch: 78, Time cost: 255.92917394638062

=>Epoch 79, learning rate = 0.0000,                     previous best = 0.6422
Epoch: 79, Iter: 0, Speed: 0.088 iter/sec, Train loss: 0.187
Epoch: 79, Iter: 100, Speed: 1.643 iter/sec, Train loss: 0.106
Epoch: 79, Iter: 200, Speed: 1.610 iter/sec, Train loss: 0.103
Epoch: 79, Iter: 300, Speed: 1.624 iter/sec, Train loss: 0.103
pixAcc: 0.795, mIoU1: 0.229
pixAcc: 0.773, mIoU2: 0.516
Epoch: 79, Time cost: 270.3337688446045
pixAcc: 0.795, mIoU1: 0.229
pixAcc: 0.773, mIoU2: 0.516

